---
title: "2018312343 염예빈 과제3"
output:
  html_document: default
  pdf_document: default
---

## 0. 라이브러리 불러오기
```{r}
library(tidyverse)
library(ggplot2)
library(data.table)
library(caret)
library(glmnet)
library(Epi)
library(glmnet)
library(MLmetrics)
```

## 1. 데이터 불러보기 및 확인
```{r cars}
data <- read.csv("C:/Users/User/Desktop/통계적모델링과머신러닝/과제3/train.csv")
data %>% summary()
data %>% str()
test <- read.csv("C:/Users/User/Desktop/통계적모델링과머신러닝/과제3/train.csv")

#table(train$Y)
```
X는 총 16개이고, Y는 범주형인것을 알 수 있습니다.
X또한 범주형과 연속형 변수가 섞여 있기에 인코딩이 필요해 보입니다.

## 2. 전처리
```{r}
train <- data
train$Y <- ifelse((train$Y == 'yes') , 1, 0)
train <- train %>% mutate_if(is.character, as.factor)

test$Y <- ifelse((test$Y == 'yes') , 1, 0)
test <- test %>% mutate_if(is.character, as.factor)

train %>% head()
```
Y변수가 Yes, No로 되어있으므로 ifelse함수를 사용하여 0과 1로 바꾸어 주었습니다.
또한 chracter인 변수들을 후의 모델링을 위해 factor변수로 바꾸어 주었습니다.

## 3.모델링
```{r}
train %>% str()
x <- model.matrix(Y~., train)[,-17]
y = train$Y

# Find the best lambda using cross-validation
set.seed(1234)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
cv.lasso$lambda.min %>% print()
# Fit the final model on the training data
model <- glmnet(x, y, alpha = 1, family = "binomial",
                lambda = cv.lasso$lambda.min)
# Display regression coefficients
coef(model)

# find cut-off point
library(pROC)
yhat = predict(model, newx=x, type='response')
lr.roc = roc(train$Y ~ yhat)
ROC(test = yhat, stat = train$Y, plot = "ROC", AUC = T, main = "Logistics Regression")
auc(lr.roc)

th = coords(lr.roc,x='best', best.method = 'closest.topleft')
th 

# check the train score
yhat1 = ifelse(yhat > th$threshold, 1, 0)
yhat2 = ifelse(yhat > 0.5, 1, 0)

confu1 <- table(real = train$Y, predict = yhat1)
confu1
F1_Score(train$Y, yhat1, positive = 1)

confu2 <- table(real = train$Y, predict = yhat2)
confu2
F1_Score(train$Y, yhat2, positive = 1)
```
모델링은 Logistic Regression을 활용해주었습니다. 변수가 많기에 Lasso를 이용하여 Penalty를 주어 변수선택을 해주었습니다
cv.lasso함수를 활용하여 최적의 람다값을 먼저 찾아주었습니다.
coef를 확인해보면 변수가 줄어든 것을 확인할 수 있습니다.

더불어, ROC커브를 활용하여 최적의 cut-off포인트를 찾아주었습니다.
결과를 확인해보면 cut-off포인트를 단순히 0.5로 정한 것 보다 f1스코어가 높은 것을 확인할 수 있습니다.

## 4. 결과
```{r}
# Make predictions on the test data
x.test <- model.matrix(Y ~., test)[,-17]
probabilities <- model %>% predict(newx = x.test)
yhat.test <- ifelse(probabilities > th$threshold, 1, 0)
yhat.test %>% head()

# score
true_y <- test$Y
mean(yhat.test == true_y)

print("confusion matrix")
confu <- table(real = true_y, predict = yhat.test)
confu
print("f1 스코어")
F1_Score(true_y, yhat.test, positive = 1)
```
test셋에 대하여 train변수와 똑같이 전처리 해준후
예측값을 도출하였습니다.
그 결과 최종 F1 스코어 0.71이 나왔습니다.